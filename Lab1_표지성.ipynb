{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "이 데이터를 가지고 평가하고 몇 가지 분류기를 사용해서 진행 \n",
    "\n",
    "수도코드를 짜서 간단한 plan을 작성\n",
    "\n",
    "single major function --> 심플하고 단순하게 다양하게 저용\n",
    "\n",
    "큰 구조를 작성하고 자동으로 작동하게 끔 진행\n",
    "\n",
    "PHW1은 다음 주까지 진행 "
   ],
   "metadata": {
    "id": "tyYdc9zmu0mn",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1.   데이터 load\n",
    "2.   데이터 cleanging\n",
    "\n",
    "결측값 확인 --> Bare Nuclei 확인 결과 ?로 결측값 존재\n",
    "\n",
    "data에 \n",
    "\n",
    "Sample code number은 불필요하다고 판단해서 제거\n",
    "\n",
    "\n",
    "3.   데이터 scaling\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "s-u6xHVVxAVX",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "GbxLsh_buknl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gOB2mb6Z0fQE",
    "outputId": "b29e065f-4569-4666-eea9-9eda5f80ed2e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"dataset/breast-cancer-wisconsin.data\",header=None)"
   ],
   "metadata": {
    "id": "4xubbiK7va2b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.columns = ['Sample code number','Clump Thickness ','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class']"
   ],
   "metadata": {
    "id": "VQO6_4-kwcDR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = df.replace('?', np.NaN)"
   ],
   "metadata": {
    "id": "wico9_U1weL0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "id": "RAuv0qLmwgOZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7544a5f7-66ee-426e-e574-4d2eb68ff877",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sample code number              0\n",
       "Clump Thickness                 0\n",
       "Uniformity of Cell Size         0\n",
       "Uniformity of Cell Shape        0\n",
       "Marginal Adhesion               0\n",
       "Single Epithelial Cell Size     0\n",
       "Bare Nuclei                    16\n",
       "Bland Chromatin                 0\n",
       "Normal Nucleoli                 0\n",
       "Mitoses                         0\n",
       "Class                           0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.fillna(0,inplace=True)"
   ],
   "metadata": {
    "id": "5XtxzTp_wiQu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "id": "dWRgELkBwj4Q",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "339b2023-330c-4062-8837-76240c162ddb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sample code number             0\n",
       "Clump Thickness                0\n",
       "Uniformity of Cell Size        0\n",
       "Uniformity of Cell Shape       0\n",
       "Marginal Adhesion              0\n",
       "Single Epithelial Cell Size    0\n",
       "Bare Nuclei                    0\n",
       "Bland Chromatin                0\n",
       "Normal Nucleoli                0\n",
       "Mitoses                        0\n",
       "Class                          0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df.drop('Sample code number', axis=1, inplace=True)"
   ],
   "metadata": {
    "id": "TEmZFKUowm7g",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X, y = df.drop(['Class'], axis=1), df['Class']"
   ],
   "metadata": {
    "id": "9cjAn69niGW2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#model, scaler, K parameter\n",
    "models = ['DecisionTreeClassifier', 'LogisticRegression', 'svm.SVC']\n",
    "scalers = [StandardScaler(), MinMaxScaler()]\n",
    "Ks = [5, 10, 15]\n",
    "\n",
    "# decision_tree_parameter\n",
    "criterions = ['gini', 'entropy']\n",
    "splitters = ['best', 'random']\n",
    "max_depths = [1, 10, 100]\n",
    "\n",
    "# logi_tree_parameter\n",
    "solvers = ['lbfgs', 'sag']\n",
    "max_iters = [50, 100, 200]\n",
    "\n",
    "# svm_parameter\n",
    "Cs = [0.1, 1]\n",
    "gammas = [0.1, 0.3, 0.5, 1, 5]\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "max_iters = [50, 100, 200]\n",
    "\n",
    "# Dictionary parameter\n",
    "dt_parameter = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [1, 10, 100]\n",
    "}\n",
    "\n",
    "lg_parameter = {\n",
    "    'solver': ['lbfgs', 'sag'],\n",
    "    'max_iter': [50, 100, 200]\n",
    "}\n",
    "\n",
    "svm_parameter = {\n",
    "    'C': [0.1, 1],\n",
    "    'gamma': [0.1, 0.3, 0.5, 1, 5],\n",
    "    'kernel': ['rbf', 'sigmoid'],\n",
    "    'max_iter': [50, 100, 200]\n",
    "}\n",
    "\n",
    "# make parameter list\n",
    "total_parameter = [scalers, Ks, criterions, splitters, max_depths, solvers, max_iters, Cs, gammas, kernels, max_iters]"
   ],
   "metadata": {
    "id": "fy6CfzYcwo0W",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_model(X, y, models, params):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "    accuracy = pd.DataFrame(columns=['model', 'scaler', 'K', 'parm', 'score'])\n",
    "\n",
    "    for model in models:\n",
    "        if model == 'DecisionTreeClassifier':\n",
    "            DT_accuracy = DT_train_model(X_train, X_test, y_train, y_test, params[0], params[1], params[2], params[3],\n",
    "                                         params[4])\n",
    "            accuracy = pd.concat([accuracy, DT_accuracy])\n",
    "            print(\"\\n\")\n",
    "        elif model == 'LogisticRegression':\n",
    "            LG_accuracy = LG_train_model(X_train, X_test, y_train, y_test, params[0], params[1], params[5], params[6])\n",
    "            accuracy = pd.concat([accuracy, LG_accuracy])\n",
    "            print(\"\\n\")\n",
    "\n",
    "        elif model == 'svm.SVC':\n",
    "            SVM_accuracy = SVM_train_model(X_train, X_test, y_train, y_test, params[0], params[1], params[7], params[8],\n",
    "                                           params[9], params[10])\n",
    "            accuracy = pd.concat([accuracy, SVM_accuracy])\n",
    "\n",
    "            print(\"\\n\")\n",
    "        else:\n",
    "            print(\"Input model Error\")\n",
    "\n",
    "    return accuracy"
   ],
   "metadata": {
    "id": "pmdNf4WAwy1S",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def DT_train_model(X_train, X_test, y_train, y_test, scalers, Ks, criterions, splitters, max_depths):\n",
    "    DT_accuracy = pd.DataFrame(columns=['model', 'scaler', 'K', 'parm', 'score'])\n",
    "\n",
    "    print(\"========================\")\n",
    "    print(\"[DecisionTreeClassifier]\")\n",
    "    print(\"========================\")\n",
    "\n",
    "    for scaler in scalers:\n",
    "        for criterion in criterions:\n",
    "            for splitter in splitters:\n",
    "                for max_depth in max_depths:\n",
    "                    for K in Ks:\n",
    "                        # do use Scaler\n",
    "                        X_train = scaler.fit_transform(X_train)\n",
    "                        X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "                        # build DecisionTreeClassifier model and fit data\n",
    "                        DT = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth,\n",
    "                                                    random_state=42)\n",
    "\n",
    "                        # do k-fold validation (cv=k)\n",
    "                        score = cross_val_score(DT, X_train, y_train, cv=K)\n",
    "                        score = np.mean(score)\n",
    "\n",
    "                        print(\n",
    "                            \"DecisionTreeClassifier Average of scores : %f (scaler = %s, k = %s, criterion = %s, splitter = %s, max_depth = %s)\" % (\n",
    "                                score, scaler, K, criterion, splitter, max_depth))\n",
    "\n",
    "                        data_to_insert = {'model': 'DecisionTreeClassifier', 'scaler': scaler, 'K': K,\n",
    "                                          'parm': '{\\'criterion\\' : %s, \\'splitter\\' : %s, \\'max_depth\\' : %s}' % (\n",
    "                                              criterion, splitter, max_depth), 'score': score}\n",
    "                        DT_accuracy = DT_accuracy.append(data_to_insert, ignore_index=True)\n",
    "\n",
    "    DT_accuracy = DT_accuracy.nlargest(5, 'score')\n",
    "    return DT_accuracy"
   ],
   "metadata": {
    "id": "zyfjvxoYw0V6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def LG_train_model(X_train, X_test, y_train, y_test, scalers, Ks, solvers, max_iters):\n",
    "    LG_accuracy = pd.DataFrame(columns=['model', 'scaler', 'K', 'parm', 'score'])\n",
    "\n",
    "    print(\"========================\")\n",
    "    print(\"[LogisticRegression]\")\n",
    "    print(\"========================\")\n",
    "\n",
    "    for scaler in scalers:\n",
    "        for solver in solvers:\n",
    "            for max_iter in max_iters:\n",
    "                for K in Ks:\n",
    "                    # do use Scaler\n",
    "                    X_train = scaler.fit_transform(X_train)\n",
    "                    X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "                    # build LogisticRegression model and fit data\n",
    "                    LG = LogisticRegression(solver=solver, max_iter=max_iter, random_state=42)\n",
    "\n",
    "                    # do k-fold validation (cv=k)\n",
    "                    score = cross_val_score(LG, X_train, y_train, cv=K)\n",
    "                    score = np.mean(score)\n",
    "\n",
    "                    print(\n",
    "                        \"LogisticRegression Average of scores : %f (scaler = %s, k = %s, solver = %s, max_iter = %s)\" % (\n",
    "                            score, scaler, K, solver, max_iter))\n",
    "\n",
    "                    data_to_insert = {'model': 'LogisticRegression', 'scaler': scaler, 'K': K,\n",
    "                                      'parm': '{\\'solver\\' : %s, \\'max_iter\\' : %s}' % (solver, max_iter),\n",
    "                                      'score': score}\n",
    "                    LG_accuracy = LG_accuracy.append(data_to_insert, ignore_index=True)\n",
    "\n",
    "    LG_accuracy = LG_accuracy.nlargest(5, 'score')\n",
    "    return LG_accuracy"
   ],
   "metadata": {
    "id": "hqYoyoYCiKko",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def SVM_train_model(X_train, X_test, y_train, y_test, scalers, Ks, Cs, gammas, kernels, max_iters):\n",
    "    SVM_accuracy = pd.DataFrame(columns=['model', 'scaler', 'K', 'parm', 'score'])\n",
    "\n",
    "    print(\"========================\")\n",
    "    print(\"[SVM]\")\n",
    "    print(\"========================\")\n",
    "    for scaler in scalers:\n",
    "        for C in Cs:\n",
    "            for gamma in gammas:\n",
    "                for kernel in kernels:\n",
    "                    for max_iter in max_iters:\n",
    "                        for K in Ks:\n",
    "                            # do use Scaler\n",
    "                            X_train = scaler.fit_transform(X_train)\n",
    "                            X_test = scaler.fit_transform(X_test)\n",
    "                            # build SVM model and fit data\n",
    "                            SVM = svm.SVC(C=C, gamma=gamma, kernel=kernel, max_iter=max_iter, random_state=42)\n",
    "\n",
    "                            # do k-fold validation (cv=k)\n",
    "                            score = cross_val_score(SVM, X_train, y_train, cv=K)\n",
    "\n",
    "                            score = np.mean(score)\n",
    "\n",
    "                            print(\n",
    "                                \"SVM Average of scores : %f (scaler = %s, k = %s, C = %s, gamma = %s, kernel = %s, max_iter = %s)\" % (\n",
    "                                    score, scaler, K, C, gamma, kernel, max_iter))\n",
    "                            data_to_insert = {'model': 'SVM', 'scaler': scaler, 'K': K,\n",
    "                                              'parm': '{\\'C\\' : %s, \\'gamma\\' : %s, \\'kernel\\' : %s, \\'max_iter\\' : %s}' % (\n",
    "                                              C, gamma, kernel, max_iter), 'score': score}\n",
    "                        SVM_accuracy = SVM_accuracy.append(data_to_insert, ignore_index=True)\n",
    "\n",
    "    SVM_accuracy = SVM_accuracy.nlargest(5, 'score')\n",
    "    return SVM_accuracy"
   ],
   "metadata": {
    "id": "pvGBfwj5iMxQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "accuracy = create_model(X, y, models, total_parameter)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZzpkJh3iNSW",
    "outputId": "272f989f-a071-43af-a5a7-91102ad792cf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 42,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========================\n",
      "[DecisionTreeClassifier]\n",
      "========================\n",
      "DecisionTreeClassifier Average of scores : 0.894418 (scaler = StandardScaler(), k = 5, criterion = gini, splitter = best, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.906948 (scaler = StandardScaler(), k = 10, criterion = gini, splitter = best, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.901470 (scaler = StandardScaler(), k = 15, criterion = gini, splitter = best, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.933752 (scaler = StandardScaler(), k = 5, criterion = gini, splitter = best, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.944545 (scaler = StandardScaler(), k = 10, criterion = gini, splitter = best, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.940920 (scaler = StandardScaler(), k = 15, criterion = gini, splitter = best, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.933752 (scaler = StandardScaler(), k = 5, criterion = gini, splitter = best, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.944545 (scaler = StandardScaler(), k = 10, criterion = gini, splitter = best, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.940920 (scaler = StandardScaler(), k = 15, criterion = gini, splitter = best, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.926625 (scaler = StandardScaler(), k = 5, criterion = gini, splitter = random, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.926656 (scaler = StandardScaler(), k = 10, criterion = gini, splitter = random, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.926648 (scaler = StandardScaler(), k = 15, criterion = gini, splitter = random, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.931998 (scaler = StandardScaler(), k = 5, criterion = gini, splitter = random, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.933831 (scaler = StandardScaler(), k = 10, criterion = gini, splitter = random, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.935420 (scaler = StandardScaler(), k = 15, criterion = gini, splitter = random, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.930196 (scaler = StandardScaler(), k = 5, criterion = gini, splitter = random, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.935617 (scaler = StandardScaler(), k = 10, criterion = gini, splitter = random, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.935420 (scaler = StandardScaler(), k = 15, criterion = gini, splitter = random, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.894418 (scaler = StandardScaler(), k = 5, criterion = entropy, splitter = best, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.901494 (scaler = StandardScaler(), k = 10, criterion = entropy, splitter = best, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.903367 (scaler = StandardScaler(), k = 15, criterion = entropy, splitter = best, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.948069 (scaler = StandardScaler(), k = 5, criterion = entropy, splitter = best, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.939221 (scaler = StandardScaler(), k = 10, criterion = entropy, splitter = best, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.946325 (scaler = StandardScaler(), k = 15, criterion = entropy, splitter = best, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.948069 (scaler = StandardScaler(), k = 5, criterion = entropy, splitter = best, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.939221 (scaler = StandardScaler(), k = 10, criterion = entropy, splitter = best, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.946325 (scaler = StandardScaler(), k = 15, criterion = entropy, splitter = best, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.926625 (scaler = StandardScaler(), k = 5, criterion = entropy, splitter = random, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.926656 (scaler = StandardScaler(), k = 10, criterion = entropy, splitter = random, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.926648 (scaler = StandardScaler(), k = 15, criterion = entropy, splitter = random, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.928427 (scaler = StandardScaler(), k = 5, criterion = entropy, splitter = random, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.942760 (scaler = StandardScaler(), k = 10, criterion = entropy, splitter = random, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.948127 (scaler = StandardScaler(), k = 15, criterion = entropy, splitter = random, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.928427 (scaler = StandardScaler(), k = 5, criterion = entropy, splitter = random, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.940974 (scaler = StandardScaler(), k = 10, criterion = entropy, splitter = random, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.946373 (scaler = StandardScaler(), k = 15, criterion = entropy, splitter = random, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.894418 (scaler = MinMaxScaler(), k = 5, criterion = gini, splitter = best, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.906948 (scaler = MinMaxScaler(), k = 10, criterion = gini, splitter = best, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.901470 (scaler = MinMaxScaler(), k = 15, criterion = gini, splitter = best, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.933752 (scaler = MinMaxScaler(), k = 5, criterion = gini, splitter = best, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.944545 (scaler = MinMaxScaler(), k = 10, criterion = gini, splitter = best, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.942722 (scaler = MinMaxScaler(), k = 15, criterion = gini, splitter = best, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.933752 (scaler = MinMaxScaler(), k = 5, criterion = gini, splitter = best, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.944545 (scaler = MinMaxScaler(), k = 10, criterion = gini, splitter = best, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.942722 (scaler = MinMaxScaler(), k = 15, criterion = gini, splitter = best, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.926625 (scaler = MinMaxScaler(), k = 5, criterion = gini, splitter = random, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.926656 (scaler = MinMaxScaler(), k = 10, criterion = gini, splitter = random, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.926648 (scaler = MinMaxScaler(), k = 15, criterion = gini, splitter = random, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.931998 (scaler = MinMaxScaler(), k = 5, criterion = gini, splitter = random, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.933831 (scaler = MinMaxScaler(), k = 10, criterion = gini, splitter = random, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.935420 (scaler = MinMaxScaler(), k = 15, criterion = gini, splitter = random, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.930196 (scaler = MinMaxScaler(), k = 5, criterion = gini, splitter = random, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.935617 (scaler = MinMaxScaler(), k = 10, criterion = gini, splitter = random, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.935420 (scaler = MinMaxScaler(), k = 15, criterion = gini, splitter = random, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.894418 (scaler = MinMaxScaler(), k = 5, criterion = entropy, splitter = best, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.901494 (scaler = MinMaxScaler(), k = 10, criterion = entropy, splitter = best, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.903367 (scaler = MinMaxScaler(), k = 15, criterion = entropy, splitter = best, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.948069 (scaler = MinMaxScaler(), k = 5, criterion = entropy, splitter = best, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.939221 (scaler = MinMaxScaler(), k = 10, criterion = entropy, splitter = best, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.946325 (scaler = MinMaxScaler(), k = 15, criterion = entropy, splitter = best, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.948069 (scaler = MinMaxScaler(), k = 5, criterion = entropy, splitter = best, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.939221 (scaler = MinMaxScaler(), k = 10, criterion = entropy, splitter = best, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.946325 (scaler = MinMaxScaler(), k = 15, criterion = entropy, splitter = best, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.926625 (scaler = MinMaxScaler(), k = 5, criterion = entropy, splitter = random, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.926656 (scaler = MinMaxScaler(), k = 10, criterion = entropy, splitter = random, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.926648 (scaler = MinMaxScaler(), k = 15, criterion = entropy, splitter = random, max_depth = 1)\n",
      "DecisionTreeClassifier Average of scores : 0.928427 (scaler = MinMaxScaler(), k = 5, criterion = entropy, splitter = random, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.942760 (scaler = MinMaxScaler(), k = 10, criterion = entropy, splitter = random, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.948127 (scaler = MinMaxScaler(), k = 15, criterion = entropy, splitter = random, max_depth = 10)\n",
      "DecisionTreeClassifier Average of scores : 0.928427 (scaler = MinMaxScaler(), k = 5, criterion = entropy, splitter = random, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.940974 (scaler = MinMaxScaler(), k = 10, criterion = entropy, splitter = random, max_depth = 100)\n",
      "DecisionTreeClassifier Average of scores : 0.946373 (scaler = MinMaxScaler(), k = 15, criterion = entropy, splitter = random, max_depth = 100)\n",
      "\n",
      "\n",
      "========================\n",
      "[LogisticRegression]\n",
      "========================\n",
      "LogisticRegression Average of scores : 0.962387 (scaler = StandardScaler(), k = 5, solver = lbfgs, max_iter = 50)\n",
      "LogisticRegression Average of scores : 0.964221 (scaler = StandardScaler(), k = 10, solver = lbfgs, max_iter = 50)\n",
      "LogisticRegression Average of scores : 0.964201 (scaler = StandardScaler(), k = 15, solver = lbfgs, max_iter = 50)\n",
      "LogisticRegression Average of scores : 0.962387 (scaler = StandardScaler(), k = 5, solver = lbfgs, max_iter = 100)\n",
      "LogisticRegression Average of scores : 0.964221 (scaler = StandardScaler(), k = 10, solver = lbfgs, max_iter = 100)\n",
      "LogisticRegression Average of scores : 0.964201 (scaler = StandardScaler(), k = 15, solver = lbfgs, max_iter = 100)\n",
      "LogisticRegression Average of scores : 0.962387 (scaler = StandardScaler(), k = 5, solver = lbfgs, max_iter = 200)\n",
      "LogisticRegression Average of scores : 0.964221 (scaler = StandardScaler(), k = 10, solver = lbfgs, max_iter = 200)\n",
      "LogisticRegression Average of scores : 0.964201 (scaler = StandardScaler(), k = 15, solver = lbfgs, max_iter = 200)\n",
      "LogisticRegression Average of scores : 0.962387 (scaler = StandardScaler(), k = 5, solver = sag, max_iter = 50)\n",
      "LogisticRegression Average of scores : 0.964221 (scaler = StandardScaler(), k = 10, solver = sag, max_iter = 50)\n",
      "LogisticRegression Average of scores : 0.964201 (scaler = StandardScaler(), k = 15, solver = sag, max_iter = 50)\n",
      "LogisticRegression Average of scores : 0.962387 (scaler = StandardScaler(), k = 5, solver = sag, max_iter = 100)\n",
      "LogisticRegression Average of scores : 0.964221 (scaler = StandardScaler(), k = 10, solver = sag, max_iter = 100)\n",
      "LogisticRegression Average of scores : 0.964201 (scaler = StandardScaler(), k = 15, solver = sag, max_iter = 100)\n",
      "LogisticRegression Average of scores : 0.962387 (scaler = StandardScaler(), k = 5, solver = sag, max_iter = 200)\n",
      "LogisticRegression Average of scores : 0.964221 (scaler = StandardScaler(), k = 10, solver = sag, max_iter = 200)\n",
      "LogisticRegression Average of scores : 0.964201 (scaler = StandardScaler(), k = 15, solver = sag, max_iter = 200)\n",
      "LogisticRegression Average of scores : 0.955228 (scaler = MinMaxScaler(), k = 5, solver = lbfgs, max_iter = 50)\n",
      "LogisticRegression Average of scores : 0.957045 (scaler = MinMaxScaler(), k = 10, solver = lbfgs, max_iter = 50)\n",
      "LogisticRegression Average of scores : 0.958843 (scaler = MinMaxScaler(), k = 15, solver = lbfgs, max_iter = 50)\n",
      "LogisticRegression Average of scores : 0.955228 (scaler = MinMaxScaler(), k = 5, solver = lbfgs, max_iter = 100)\n",
      "LogisticRegression Average of scores : 0.957045 (scaler = MinMaxScaler(), k = 10, solver = lbfgs, max_iter = 100)\n",
      "LogisticRegression Average of scores : 0.958843 (scaler = MinMaxScaler(), k = 15, solver = lbfgs, max_iter = 100)\n",
      "LogisticRegression Average of scores : 0.955228 (scaler = MinMaxScaler(), k = 5, solver = lbfgs, max_iter = 200)\n",
      "LogisticRegression Average of scores : 0.957045 (scaler = MinMaxScaler(), k = 10, solver = lbfgs, max_iter = 200)\n",
      "LogisticRegression Average of scores : 0.958843 (scaler = MinMaxScaler(), k = 15, solver = lbfgs, max_iter = 200)\n",
      "LogisticRegression Average of scores : 0.955228 (scaler = MinMaxScaler(), k = 5, solver = sag, max_iter = 50)\n",
      "LogisticRegression Average of scores : 0.957045 (scaler = MinMaxScaler(), k = 10, solver = sag, max_iter = 50)\n",
      "LogisticRegression Average of scores : 0.958843 (scaler = MinMaxScaler(), k = 15, solver = sag, max_iter = 50)\n",
      "LogisticRegression Average of scores : 0.955228 (scaler = MinMaxScaler(), k = 5, solver = sag, max_iter = 100)\n",
      "LogisticRegression Average of scores : 0.957045 (scaler = MinMaxScaler(), k = 10, solver = sag, max_iter = 100)\n",
      "LogisticRegression Average of scores : 0.958843 (scaler = MinMaxScaler(), k = 15, solver = sag, max_iter = 100)\n",
      "LogisticRegression Average of scores : 0.955228 (scaler = MinMaxScaler(), k = 5, solver = sag, max_iter = 200)\n",
      "LogisticRegression Average of scores : 0.957045 (scaler = MinMaxScaler(), k = 10, solver = sag, max_iter = 200)\n",
      "LogisticRegression Average of scores : 0.958843 (scaler = MinMaxScaler(), k = 15, solver = sag, max_iter = 200)\n",
      "\n",
      "\n",
      "========================\n",
      "[SVM]\n",
      "========================\n",
      "SVM Average of scores : 0.964189 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.964188 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.964201 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.964189 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.964188 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.964201 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.964189 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.964188 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.964201 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.965959 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.967760 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.967757 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.965959 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.965974 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.966003 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.965959 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.965974 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.966003 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.951657 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.951688 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.953390 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.951657 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.949903 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.951588 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.949871 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.951688 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.951588 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.965959 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.969545 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.971361 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.964173 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.967760 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.967757 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.964173 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.967760 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.967757 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.951673 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.953506 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.951636 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.946300 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.944545 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.944571 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.946300 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.946331 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.946373 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.965975 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.967760 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.965955 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.962403 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.969545 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.969559 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.962403 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.969545 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.969559 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.940943 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.949903 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.949834 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.935569 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.937370 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.935609 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.935569 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.935584 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.935609 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.965975 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.967792 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.971313 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.965975 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.966006 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.969559 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.965975 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.966006 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.969559 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.931998 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.944545 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.942722 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.881885 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.896234 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.898151 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.649373 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.649383 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.649360 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.969546 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.964188 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.973115 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.967761 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.964188 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.973115 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.967761 (scaler = StandardScaler(), k = 5, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.964188 (scaler = StandardScaler(), k = 10, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.973115 (scaler = StandardScaler(), k = 15, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.962403 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.967760 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.967757 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.962403 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.967760 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.967757 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.962403 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.967760 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.967757 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.958816 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.958831 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.958890 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.958816 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.958831 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.958890 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.958816 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.958831 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.958890 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.957030 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.3, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.957078 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.3, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.958843 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.3, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.957030 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.3, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.955260 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.3, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.957041 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.3, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.957030 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.3, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.955260 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.3, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.957041 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.3, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.939157 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.955195 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.950024 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.939157 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.951623 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.950024 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.939157 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.951623 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.950024 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.957030 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.958831 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.958796 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.960602 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.960617 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.960550 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.960602 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.960617 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.960550 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.955228 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.956981 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.955334 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.955228 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.953409 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.955334 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.955228 (scaler = StandardScaler(), k = 5, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.953409 (scaler = StandardScaler(), k = 10, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.955334 (scaler = StandardScaler(), k = 15, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.958816 (scaler = StandardScaler(), k = 5, C = 1, gamma = 1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.958831 (scaler = StandardScaler(), k = 10, C = 1, gamma = 1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.958748 (scaler = StandardScaler(), k = 15, C = 1, gamma = 1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.953459 (scaler = StandardScaler(), k = 5, C = 1, gamma = 1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.955292 (scaler = StandardScaler(), k = 10, C = 1, gamma = 1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.955192 (scaler = StandardScaler(), k = 15, C = 1, gamma = 1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.949887 (scaler = StandardScaler(), k = 5, C = 1, gamma = 1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.951688 (scaler = StandardScaler(), k = 10, C = 1, gamma = 1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.953390 (scaler = StandardScaler(), k = 15, C = 1, gamma = 1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.953411 (scaler = StandardScaler(), k = 5, C = 1, gamma = 1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.948052 (scaler = StandardScaler(), k = 10, C = 1, gamma = 1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.951731 (scaler = StandardScaler(), k = 15, C = 1, gamma = 1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.951625 (scaler = StandardScaler(), k = 5, C = 1, gamma = 1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.948052 (scaler = StandardScaler(), k = 10, C = 1, gamma = 1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.948222 (scaler = StandardScaler(), k = 15, C = 1, gamma = 1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.951625 (scaler = StandardScaler(), k = 5, C = 1, gamma = 1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.948052 (scaler = StandardScaler(), k = 10, C = 1, gamma = 1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.948222 (scaler = StandardScaler(), k = 15, C = 1, gamma = 1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.948102 (scaler = StandardScaler(), k = 5, C = 1, gamma = 5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.951656 (scaler = StandardScaler(), k = 10, C = 1, gamma = 5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.951541 (scaler = StandardScaler(), k = 15, C = 1, gamma = 5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.919450 (scaler = StandardScaler(), k = 5, C = 1, gamma = 5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.928442 (scaler = StandardScaler(), k = 10, C = 1, gamma = 5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.928402 (scaler = StandardScaler(), k = 15, C = 1, gamma = 5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.899759 (scaler = StandardScaler(), k = 5, C = 1, gamma = 5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.903377 (scaler = StandardScaler(), k = 10, C = 1, gamma = 5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.905263 (scaler = StandardScaler(), k = 15, C = 1, gamma = 5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.946332 (scaler = StandardScaler(), k = 5, C = 1, gamma = 5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.958831 (scaler = StandardScaler(), k = 10, C = 1, gamma = 5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.964154 (scaler = StandardScaler(), k = 15, C = 1, gamma = 5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.946332 (scaler = StandardScaler(), k = 5, C = 1, gamma = 5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.958831 (scaler = StandardScaler(), k = 10, C = 1, gamma = 5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.964154 (scaler = StandardScaler(), k = 15, C = 1, gamma = 5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.946332 (scaler = StandardScaler(), k = 5, C = 1, gamma = 5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.958831 (scaler = StandardScaler(), k = 10, C = 1, gamma = 5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.964154 (scaler = StandardScaler(), k = 15, C = 1, gamma = 5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.964173 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.971364 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.971313 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.958800 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.958831 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.962399 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.958800 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.958831 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.962399 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.971348 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.971364 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.971313 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.949839 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.962403 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.962399 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.948053 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.949870 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.948080 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.967745 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.969545 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.967757 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.962371 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.964188 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.962399 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.962371 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.964188 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.962399 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.3, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.969546 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.973149 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.971313 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.964173 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.964188 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.964201 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.964173 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.964188 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.964201 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.3, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.965959 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.969545 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.969559 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.964173 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.967760 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.967805 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.964173 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.967760 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.967805 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.960618 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.957045 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.957041 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.971364 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.967792 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.966003 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.971364 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.969578 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.969559 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 0.5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.969546 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.969545 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.969559 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.969546 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.969545 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.969559 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.969546 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.969545 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.969559 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.559797 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.531169 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.527881 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.720866 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.685065 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.683594 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.767375 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.765617 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.762304 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.955245 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.955292 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.955192 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.946300 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.946331 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.948174 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.946300 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.948117 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.948174 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.035779 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.035779 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.037648 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.041136 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.039351 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.039403 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.574260 (scaler = MinMaxScaler(), k = 5, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.563506 (scaler = MinMaxScaler(), k = 10, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.556472 (scaler = MinMaxScaler(), k = 15, C = 0.1, gamma = 5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.965959 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.964188 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.964201 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.965959 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.964188 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.964201 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.965959 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.964188 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.964201 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.962371 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.964188 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.962399 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.962371 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.962403 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.962399 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.962371 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.962403 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.962399 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.965975 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.3, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.964188 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.3, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.965955 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.3, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.965975 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.3, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.964188 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.3, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.965955 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.3, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.965975 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.3, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.964188 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.3, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.965955 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.3, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.967745 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.964188 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.964248 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.967745 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.965974 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.964201 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.967745 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.965974 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.964201 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.3, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.967761 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.967760 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.967757 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.967761 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.967760 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.967757 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.967761 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.967760 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.967757 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.924855 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.923084 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.923092 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.924855 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.923084 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.923092 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.924855 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.923084 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.923092 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 0.5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.964189 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.969578 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.971361 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 1, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.964189 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.969578 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.971361 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 1, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.964189 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.969578 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.971361 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 1, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.559797 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.531169 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.527881 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 1, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.670737 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.676136 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.669322 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 1, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.670737 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.676136 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.671124 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 1, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.958816 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.957045 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.958843 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 5, kernel = rbf, max_iter = 50)\n",
      "SVM Average of scores : 0.958816 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.962435 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.962352 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 5, kernel = rbf, max_iter = 100)\n",
      "SVM Average of scores : 0.960602 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.962435 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.962352 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 5, kernel = rbf, max_iter = 200)\n",
      "SVM Average of scores : 0.035779 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.035779 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.037648 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 5, kernel = sigmoid, max_iter = 50)\n",
      "SVM Average of scores : 0.041136 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.039351 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.039403 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 5, kernel = sigmoid, max_iter = 100)\n",
      "SVM Average of scores : 0.338192 (scaler = MinMaxScaler(), k = 5, C = 1, gamma = 5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.334610 (scaler = MinMaxScaler(), k = 10, C = 1, gamma = 5, kernel = sigmoid, max_iter = 200)\n",
      "SVM Average of scores : 0.332670 (scaler = MinMaxScaler(), k = 15, C = 1, gamma = 5, kernel = sigmoid, max_iter = 200)\n",
      "\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# sort value by score by descending order\n",
    "accuracy = accuracy.sort_values(by=['score'], ascending=False)\n",
    "\n",
    "# reset index number and restore\n",
    "accuracy = accuracy.reset_index(drop=True)\n",
    "\n",
    "accuracy"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "-0Mvbr1tiPrI",
    "outputId": "59f485b8-70c1-4dfa-ed33-34ef02f2ef10",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 43,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     model            scaler   K  \\\n",
       "0                      SVM  StandardScaler()  15   \n",
       "1                      SVM  StandardScaler()  15   \n",
       "2                      SVM  StandardScaler()  15   \n",
       "3                      SVM  StandardScaler()  15   \n",
       "4                      SVM    MinMaxScaler()  15   \n",
       "5       LogisticRegression  StandardScaler()  10   \n",
       "6       LogisticRegression  StandardScaler()  10   \n",
       "7       LogisticRegression  StandardScaler()  10   \n",
       "8       LogisticRegression  StandardScaler()  10   \n",
       "9       LogisticRegression  StandardScaler()  10   \n",
       "10  DecisionTreeClassifier  StandardScaler()  15   \n",
       "11  DecisionTreeClassifier    MinMaxScaler()  15   \n",
       "12  DecisionTreeClassifier  StandardScaler()   5   \n",
       "13  DecisionTreeClassifier  StandardScaler()   5   \n",
       "14  DecisionTreeClassifier    MinMaxScaler()   5   \n",
       "\n",
       "                                                               parm     score  \n",
       "0     {'C' : 0.1, 'gamma' : 5, 'kernel' : sigmoid, 'max_iter' : 50}  0.973115  \n",
       "1    {'C' : 0.1, 'gamma' : 5, 'kernel' : sigmoid, 'max_iter' : 100}  0.973115  \n",
       "2    {'C' : 0.1, 'gamma' : 5, 'kernel' : sigmoid, 'max_iter' : 200}  0.973115  \n",
       "3   {'C' : 0.1, 'gamma' : 0.3, 'kernel' : sigmoid, 'max_iter' : 50}  0.971361  \n",
       "4           {'C' : 1, 'gamma' : 1, 'kernel' : rbf, 'max_iter' : 50}  0.971361  \n",
       "5                               {'solver' : lbfgs, 'max_iter' : 50}  0.964221  \n",
       "6                              {'solver' : lbfgs, 'max_iter' : 100}  0.964221  \n",
       "7                              {'solver' : lbfgs, 'max_iter' : 200}  0.964221  \n",
       "8                                 {'solver' : sag, 'max_iter' : 50}  0.964221  \n",
       "9                                {'solver' : sag, 'max_iter' : 100}  0.964221  \n",
       "10   {'criterion' : entropy, 'splitter' : random, 'max_depth' : 10}  0.948127  \n",
       "11   {'criterion' : entropy, 'splitter' : random, 'max_depth' : 10}  0.948127  \n",
       "12     {'criterion' : entropy, 'splitter' : best, 'max_depth' : 10}  0.948069  \n",
       "13    {'criterion' : entropy, 'splitter' : best, 'max_depth' : 100}  0.948069  \n",
       "14     {'criterion' : entropy, 'splitter' : best, 'max_depth' : 10}  0.948069  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-675ac324-e093-4f3e-8328-09cf2dfa5e4b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>scaler</th>\n",
       "      <th>K</th>\n",
       "      <th>parm</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>15</td>\n",
       "      <td>{'C' : 0.1, 'gamma' : 5, 'kernel' : sigmoid, 'max_iter' : 50}</td>\n",
       "      <td>0.973115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>15</td>\n",
       "      <td>{'C' : 0.1, 'gamma' : 5, 'kernel' : sigmoid, 'max_iter' : 100}</td>\n",
       "      <td>0.973115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>15</td>\n",
       "      <td>{'C' : 0.1, 'gamma' : 5, 'kernel' : sigmoid, 'max_iter' : 200}</td>\n",
       "      <td>0.973115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>15</td>\n",
       "      <td>{'C' : 0.1, 'gamma' : 0.3, 'kernel' : sigmoid, 'max_iter' : 50}</td>\n",
       "      <td>0.971361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>15</td>\n",
       "      <td>{'C' : 1, 'gamma' : 1, 'kernel' : rbf, 'max_iter' : 50}</td>\n",
       "      <td>0.971361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>10</td>\n",
       "      <td>{'solver' : lbfgs, 'max_iter' : 50}</td>\n",
       "      <td>0.964221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>10</td>\n",
       "      <td>{'solver' : lbfgs, 'max_iter' : 100}</td>\n",
       "      <td>0.964221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>10</td>\n",
       "      <td>{'solver' : lbfgs, 'max_iter' : 200}</td>\n",
       "      <td>0.964221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>10</td>\n",
       "      <td>{'solver' : sag, 'max_iter' : 50}</td>\n",
       "      <td>0.964221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>10</td>\n",
       "      <td>{'solver' : sag, 'max_iter' : 100}</td>\n",
       "      <td>0.964221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>15</td>\n",
       "      <td>{'criterion' : entropy, 'splitter' : random, 'max_depth' : 10}</td>\n",
       "      <td>0.948127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>15</td>\n",
       "      <td>{'criterion' : entropy, 'splitter' : random, 'max_depth' : 10}</td>\n",
       "      <td>0.948127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'criterion' : entropy, 'splitter' : best, 'max_depth' : 10}</td>\n",
       "      <td>0.948069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'criterion' : entropy, 'splitter' : best, 'max_depth' : 100}</td>\n",
       "      <td>0.948069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>5</td>\n",
       "      <td>{'criterion' : entropy, 'splitter' : best, 'max_depth' : 10}</td>\n",
       "      <td>0.948069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-675ac324-e093-4f3e-8328-09cf2dfa5e4b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-675ac324-e093-4f3e-8328-09cf2dfa5e4b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-675ac324-e093-4f3e-8328-09cf2dfa5e4b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# checking model parameter\n",
    "def check_model(X, y, models, scalers, Ks, dt_parameter, lg_parameter, svm_parameter):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "    accuracy = pd.DataFrame(columns=['model', 'scaler', 'K', 'parm', 'score'])\n",
    "\n",
    "    for model in models:\n",
    "        if model == 'DecisionTreeClassifier':\n",
    "            DT_accuracy = DT_grid_model(X_train, X_test, y_train, y_test, scalers, Ks, dt_parameter)\n",
    "            accuracy = pd.concat([accuracy, DT_accuracy])\n",
    "            print(\"\\n\")\n",
    "        elif model == 'LogisticRegression':\n",
    "            LG_accuracy = LG_grid_model(X_train, X_test, y_train, y_test, scalers, Ks, lg_parameter)\n",
    "            accuracy = pd.concat([accuracy, LG_accuracy])\n",
    "            print(\"\\n\")\n",
    "\n",
    "        elif model == 'svm.SVC':\n",
    "            SVM_accuracy = SVM_grid_model(X_train, X_test, y_train, y_test, scalers, Ks, svm_parameter)\n",
    "            accuracy = pd.concat([accuracy, SVM_accuracy])\n",
    "\n",
    "            print(\"\\n\")\n",
    "        else:\n",
    "            print(\"Input model Error\")\n",
    "\n",
    "    return accuracy"
   ],
   "metadata": {
    "id": "kHkExHMEiRvm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def DT_grid_model(X_train, X_test, y_train, y_test, scalers, Ks, dt_parameter):\n",
    "    DT_accuracy = pd.DataFrame(columns=['model', 'scaler', 'K', 'parm', 'score'])\n",
    "\n",
    "    print(\"==========================================\")\n",
    "    print(\"[DecisionTreeClassifier With GridSearchCV]\")\n",
    "    print(\"==========================================\")\n",
    "\n",
    "    for scaler in scalers:\n",
    "        print(\"------------------------------------------\")\n",
    "        print(\"[%s]\" % scaler)\n",
    "        print(\"------------------------------------------\")\n",
    "\n",
    "        for K in Ks:\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.fit_transform(X_test)\n",
    "            DT = DecisionTreeClassifier(random_state=42);\n",
    "            grid_DT = GridSearchCV(DT, param_grid=dt_parameter, cv=K, scoring=\"accuracy\")\n",
    "            grid_DT.fit(X_train, y_train)\n",
    "\n",
    "            print('GridSearchCV Best parameters (using k : %s) : ' % K, grid_DT.best_params_)\n",
    "            print('GridSearchCV Best accuracy : %0.6f' % grid_DT.best_score_)\n",
    "\n",
    "            data_to_insert = {'model': 'DecisionTreeClassifier', 'scaler': scaler, 'K': K,\n",
    "                              'parm': grid_DT.best_params_, 'score': grid_DT.best_score_}\n",
    "            DT_accuracy = DT_accuracy.append(data_to_insert, ignore_index=True)\n",
    "\n",
    "    DT_accuracy = DT_accuracy.nlargest(1, 'score')\n",
    "    return DT_accuracy\n"
   ],
   "metadata": {
    "id": "Gtw_NAtpiSPq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def LG_grid_model(X_train, X_test, y_train, y_test, scalers, Ks, lg_parameter):\n",
    "    LG_accuracy = pd.DataFrame(columns=['model', 'scaler', 'K', 'parm', 'score'])\n",
    "\n",
    "    print(\"==========================================\")\n",
    "    print(\"[LogisticRegression With GridSearchCV]\")\n",
    "    print(\"==========================================\")\n",
    "\n",
    "    for scaler in scalers:\n",
    "        print(\"------------------------------------------\")\n",
    "        print(\"[%s]\" % scaler)\n",
    "        print(\"------------------------------------------\")\n",
    "\n",
    "        for K in Ks:\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.fit_transform(X_test)\n",
    "            LG = LogisticRegression(random_state=42);\n",
    "            grid_LG = GridSearchCV(LG, param_grid=lg_parameter, cv=K, scoring=\"accuracy\")\n",
    "            grid_LG.fit(X_train, y_train)\n",
    "\n",
    "            print('GridSearchCV Best parameters (using k : %s) : ' % K, grid_LG.best_params_)\n",
    "            print('GridSearchCV Best accuracy : %0.6f' % grid_LG.best_score_)\n",
    "\n",
    "            data_to_insert = {'model': 'LogisticRegression', 'scaler': scaler, 'K': K,\n",
    "                              'parm': grid_LG.best_params_, 'score': grid_LG.best_score_}\n",
    "            LG_accuracy = LG_accuracy.append(data_to_insert, ignore_index=True)\n",
    "\n",
    "    LG_accuracy = LG_accuracy.nlargest(1, 'score')\n",
    "    return LG_accuracy"
   ],
   "metadata": {
    "id": "1PMJdIEtiTVt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def SVM_grid_model(X_train, X_test, y_train, y_test, scalers, Ks, svm_parameter):\n",
    "    SVM_accuracy = pd.DataFrame(columns=['model', 'scaler', 'K', 'parm', 'score'])\n",
    "\n",
    "    print(\"==========================================\")\n",
    "    print(\"[SVM With GridSearchCV]\")\n",
    "    print(\"==========================================\")\n",
    "\n",
    "    for scaler in scalers:\n",
    "        print(\"------------------------------------------\")\n",
    "        print(\"[%s]\" % scaler)\n",
    "        print(\"------------------------------------------\")\n",
    "        for K in Ks:\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.fit_transform(X_test)\n",
    "            SVM = svm.SVC(random_state=42);\n",
    "            grid_SVM = GridSearchCV(SVM, param_grid=svm_parameter, cv=K, scoring=\"accuracy\")\n",
    "            grid_SVM.fit(X_train, y_train)\n",
    "\n",
    "            print('GridSearchCV Best parameters (using k : %s) : ' % K, grid_SVM.best_params_)\n",
    "            print('GridSearchCV Best accuracy : %0.6f' % grid_SVM.best_score_)\n",
    "            data_to_insert = {'model': 'SVM', 'scaler': scaler, 'K': K,\n",
    "                              'parm': grid_SVM.best_params_, 'score': grid_SVM.best_score_}\n",
    "            SVM_accuracy = SVM_accuracy.append(data_to_insert, ignore_index=True)\n",
    "\n",
    "    SVM_accuracy = SVM_accuracy.nlargest(1, 'score')\n",
    "    return SVM_accuracy"
   ],
   "metadata": {
    "id": "E-_bVLpxiUbQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 47,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "grid_accuracy = check_model(X, y, models, scalers, Ks, dt_parameter, lg_parameter, svm_parameter)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xZtw4NeziV1N",
    "outputId": "199f0160-89b8-408d-9beb-59828676cdac",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==========================================\n",
      "[DecisionTreeClassifier With GridSearchCV]\n",
      "==========================================\n",
      "------------------------------------------\n",
      "[StandardScaler()]\n",
      "------------------------------------------\n",
      "GridSearchCV Best parameters (using k : 5) :  {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'best'}\n",
      "GridSearchCV Best accuracy : 0.948069\n",
      "GridSearchCV Best parameters (using k : 10) :  {'criterion': 'gini', 'max_depth': 10, 'splitter': 'best'}\n",
      "GridSearchCV Best accuracy : 0.944545\n",
      "GridSearchCV Best parameters (using k : 15) :  {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'random'}\n",
      "GridSearchCV Best accuracy : 0.948127\n",
      "------------------------------------------\n",
      "[MinMaxScaler()]\n",
      "------------------------------------------\n",
      "GridSearchCV Best parameters (using k : 5) :  {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'best'}\n",
      "GridSearchCV Best accuracy : 0.948069\n",
      "GridSearchCV Best parameters (using k : 10) :  {'criterion': 'gini', 'max_depth': 10, 'splitter': 'best'}\n",
      "GridSearchCV Best accuracy : 0.944545\n",
      "GridSearchCV Best parameters (using k : 15) :  {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'random'}\n",
      "GridSearchCV Best accuracy : 0.948127\n",
      "\n",
      "\n",
      "==========================================\n",
      "[LogisticRegression With GridSearchCV]\n",
      "==========================================\n",
      "------------------------------------------\n",
      "[StandardScaler()]\n",
      "------------------------------------------\n",
      "GridSearchCV Best parameters (using k : 5) :  {'max_iter': 50, 'solver': 'lbfgs'}\n",
      "GridSearchCV Best accuracy : 0.962387\n",
      "GridSearchCV Best parameters (using k : 10) :  {'max_iter': 50, 'solver': 'lbfgs'}\n",
      "GridSearchCV Best accuracy : 0.964221\n",
      "GridSearchCV Best parameters (using k : 15) :  {'max_iter': 50, 'solver': 'lbfgs'}\n",
      "GridSearchCV Best accuracy : 0.964201\n",
      "------------------------------------------\n",
      "[MinMaxScaler()]\n",
      "------------------------------------------\n",
      "GridSearchCV Best parameters (using k : 5) :  {'max_iter': 50, 'solver': 'lbfgs'}\n",
      "GridSearchCV Best accuracy : 0.955228\n",
      "GridSearchCV Best parameters (using k : 10) :  {'max_iter': 50, 'solver': 'lbfgs'}\n",
      "GridSearchCV Best accuracy : 0.957045\n",
      "GridSearchCV Best parameters (using k : 15) :  {'max_iter': 50, 'solver': 'lbfgs'}\n",
      "GridSearchCV Best accuracy : 0.958843\n",
      "\n",
      "\n",
      "==========================================\n",
      "[SVM With GridSearchCV]\n",
      "==========================================\n",
      "------------------------------------------\n",
      "[StandardScaler()]\n",
      "------------------------------------------\n",
      "GridSearchCV Best parameters (using k : 5) :  {'C': 0.1, 'gamma': 5, 'kernel': 'sigmoid', 'max_iter': 50}\n",
      "GridSearchCV Best accuracy : 0.969546\n",
      "GridSearchCV Best parameters (using k : 10) :  {'C': 0.1, 'gamma': 0.3, 'kernel': 'sigmoid', 'max_iter': 50}\n",
      "GridSearchCV Best accuracy : 0.969545\n",
      "GridSearchCV Best parameters (using k : 15) :  {'C': 0.1, 'gamma': 5, 'kernel': 'sigmoid', 'max_iter': 50}\n",
      "GridSearchCV Best accuracy : 0.973115\n",
      "------------------------------------------\n",
      "[MinMaxScaler()]\n",
      "------------------------------------------\n",
      "GridSearchCV Best parameters (using k : 5) :  {'C': 0.1, 'gamma': 0.5, 'kernel': 'sigmoid', 'max_iter': 100}\n",
      "GridSearchCV Best accuracy : 0.971364\n",
      "GridSearchCV Best parameters (using k : 10) :  {'C': 0.1, 'gamma': 0.3, 'kernel': 'sigmoid', 'max_iter': 50}\n",
      "GridSearchCV Best accuracy : 0.973149\n",
      "GridSearchCV Best parameters (using k : 15) :  {'C': 1, 'gamma': 1, 'kernel': 'rbf', 'max_iter': 50}\n",
      "GridSearchCV Best accuracy : 0.971361\n",
      "\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# sort value by score by descending order\n",
    "grid_accuracy = grid_accuracy.sort_values(by=['score'], ascending=False)\n",
    "\n",
    "# reset index number and restore\n",
    "grid_accuracy = grid_accuracy.reset_index(drop=True)\n",
    "\n",
    "grid_accuracy"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "8al1Bs5jiZvO",
    "outputId": "d85977cf-2058-4efe-e0e3-5073792774b8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    model            scaler   K  \\\n",
       "0                     SVM    MinMaxScaler()  10   \n",
       "1      LogisticRegression  StandardScaler()  10   \n",
       "2  DecisionTreeClassifier  StandardScaler()  15   \n",
       "\n",
       "                                                              parm     score  \n",
       "0    {'C': 0.1, 'gamma': 0.3, 'kernel': 'sigmoid', 'max_iter': 50}  0.973149  \n",
       "1                              {'max_iter': 50, 'solver': 'lbfgs'}  0.964221  \n",
       "2  {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'random'}  0.948127  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-04a102e2-fd87-488a-998c-91eb63481e9e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>scaler</th>\n",
       "      <th>K</th>\n",
       "      <th>parm</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 0.1, 'gamma': 0.3, 'kernel': 'sigmoid', 'max_iter': 50}</td>\n",
       "      <td>0.973149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_iter': 50, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.964221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>15</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'splitter': 'random'}</td>\n",
       "      <td>0.948127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04a102e2-fd87-488a-998c-91eb63481e9e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-04a102e2-fd87-488a-998c-91eb63481e9e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-04a102e2-fd87-488a-998c-91eb63481e9e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# now we know the best parameters with GridSearchCV\n",
    "# Analysis the model\n",
    "\n",
    "print(\"========================\")\n",
    "print(\"[DecisionTreeClassifier]\")\n",
    "print(\"========================\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = grid_accuracy[grid_accuracy['model'] == 'DecisionTreeClassifier'].scaler\n",
    "scaler = scaler.array[0]\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "parm = grid_accuracy[grid_accuracy['model'] == 'DecisionTreeClassifier'].parm\n",
    "parm_dic = parm.array[0]\n",
    "\n",
    "DT = DecisionTreeClassifier(criterion=parm_dic['criterion'], max_depth=parm_dic['max_depth'],\n",
    "                            splitter=parm_dic['splitter'], random_state=42);\n",
    "DT.fit(X_train, y_train)\n",
    "y_pred = DT.predict(X_test)\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"parameters\")\n",
    "print(\"------------------------\")\n",
    "print(DT.get_params())\n",
    "print()\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"Accuracy\")\n",
    "print(\"------------------------\")\n",
    "print(\"Accuracy score (training) : %0.6f\" % DT.score(X_train, y_train))\n",
    "print(\"Accuracy score (testing) : %0.6f\" % DT.score(X_test, y_test))  # same score -> accuracy_score(y_test, y_pred)\n",
    "\n",
    "dt_cf = confusion_matrix(y_test, y_pred)\n",
    "dt_mat = pd.DataFrame(dt_cf)\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.title('DecisionTreeClassifier Confusion Matrix')\n",
    "sns.heatmap(dt_mat, annot=True, fmt='.1f')\n",
    "plt.show()\n",
    "\n",
    "print(\"---------------------\")\n",
    "print(\"Classification Report\")\n",
    "print(\"---------------------\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "id": "0iPOi3r2iXpn",
    "outputId": "5965be8a-ad0f-4715-8948-9c22fa4061b9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 50,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========================\n",
      "[DecisionTreeClassifier]\n",
      "========================\n",
      "------------------------\n",
      "parameters\n",
      "------------------------\n",
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'random'}\n",
      "\n",
      "------------------------\n",
      "Accuracy\n",
      "------------------------\n",
      "Accuracy score (training) : 1.000000\n",
      "Accuracy score (testing) : 0.921429\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 360x216 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------------------\n",
      "Classification Report\n",
      "---------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.93      0.96      0.94        95\n",
      "           4       0.90      0.84      0.87        45\n",
      "\n",
      "    accuracy                           0.92       140\n",
      "   macro avg       0.92      0.90      0.91       140\n",
      "weighted avg       0.92      0.92      0.92       140\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"========================\")\n",
    "print(\"[LogisticRegression]\")\n",
    "print(\"========================\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = grid_accuracy[grid_accuracy['model'] == 'LogisticRegression'].scaler\n",
    "scaler = scaler.array[0]\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "parm = grid_accuracy[grid_accuracy['model'] == 'LogisticRegression'].parm\n",
    "parm_dic = parm.array[0]\n",
    "\n",
    "LG = LogisticRegression(max_iter=parm_dic['max_iter'], solver=parm_dic['solver'], random_state=42);\n",
    "LG.fit(X_train, y_train)\n",
    "y_pred = LG.predict(X_test)\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"parameters\")\n",
    "print(\"------------------------\")\n",
    "print(LG.get_params())\n",
    "print()\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"Accuracy\")\n",
    "print(\"------------------------\")\n",
    "print(\"Accuracy score (training) : %0.6f\" % LG.score(X_train, y_train))\n",
    "print(\"Accuracy score (testing) : %0.6f\" % LG.score(X_test, y_test))  # same score -> accuracy_score(y_test, y_pred)\n",
    "\n",
    "lg_cf = confusion_matrix(y_test, y_pred)\n",
    "lg_cf_mat = pd.DataFrame(lg_cf)\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.title('LogisticRegression Confusion Matrix')\n",
    "sns.heatmap(lg_cf_mat, annot=True, fmt='.1f')\n",
    "plt.show()\n",
    "\n",
    "print(\"---------------------\")\n",
    "print(\"Classification Report\")\n",
    "print(\"---------------------\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "id": "4bfS_Zr3idTV",
    "outputId": "1f4ac98c-84b6-4976-b276-b46829e7b9d5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 51,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========================\n",
      "[LogisticRegression]\n",
      "========================\n",
      "------------------------\n",
      "parameters\n",
      "------------------------\n",
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 50, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "------------------------\n",
      "Accuracy\n",
      "------------------------\n",
      "Accuracy score (training) : 0.969589\n",
      "Accuracy score (testing) : 0.971429\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 360x216 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------------------\n",
      "Classification Report\n",
      "---------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.97      0.99      0.98        95\n",
      "           4       0.98      0.93      0.95        45\n",
      "\n",
      "    accuracy                           0.97       140\n",
      "   macro avg       0.97      0.96      0.97       140\n",
      "weighted avg       0.97      0.97      0.97       140\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"========================\")\n",
    "print(\"[SVM]\")\n",
    "print(\"========================\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = grid_accuracy[grid_accuracy['model'] == 'SVM'].scaler\n",
    "scaler = scaler.array[0]\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "parm = grid_accuracy[grid_accuracy['model'] == 'SVM'].parm\n",
    "parm_dic = parm.array[0]\n",
    "\n",
    "SVM = svm.SVC(C=parm_dic['C'], gamma=parm_dic['gamma'], kernel=parm_dic['kernel'],\n",
    "                        max_iter=parm_dic['max_iter'], random_state=42);\n",
    "SVM.fit(X_train, y_train)\n",
    "y_pred = SVM.predict(X_test)\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"parameters\")\n",
    "print(\"------------------------\")\n",
    "print(SVM.get_params())\n",
    "print()\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"Accuracy\")\n",
    "print(\"------------------------\")\n",
    "print(\"Accuracy score (training) : %0.6f\" % SVM.score(X_train, y_train))\n",
    "print(\"Accuracy score (testing) : %0.6f\" % SVM.score(X_test, y_test))  # same score -> accuracy_score(y_test, y_pred)\n",
    "\n",
    "svm_cf = confusion_matrix(y_test, y_pred)\n",
    "svm_cf_mat = pd.DataFrame(lg_cf)\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.title('SVM Confusion Matrix')\n",
    "sns.heatmap(svm_cf_mat, annot=True, fmt='.1f')\n",
    "plt.show()\n",
    "\n",
    "print(\"---------------------\")\n",
    "print(\"Classification Report\")\n",
    "print(\"---------------------\")\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "id": "TSL4xZVmiett",
    "outputId": "186f5749-9844-46d4-82d1-e1a6bb81d5d7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 52,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "========================\n",
      "[SVM]\n",
      "========================\n",
      "------------------------\n",
      "parameters\n",
      "------------------------\n",
      "{'C': 0.1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.3, 'kernel': 'sigmoid', 'max_iter': 50, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "------------------------\n",
      "Accuracy\n",
      "------------------------\n",
      "Accuracy score (training) : 0.973166\n",
      "Accuracy score (testing) : 0.978571\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 360x216 with 2 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASgAAADSCAYAAAD5eV3SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAV8ElEQVR4nO3deZgV1ZnH8e8LzaZCI4usboyowRWDosEFxSioBEeNooioOEQTNEZmoibjJDHqGBMVNSYZEGWJsii4gkZFRUXFBdxxQYLQQCMIDQRR6O53/qgCbzXdXZfu5t6D/D7PU49ddU6dem+39+WcU+fWNXdHRCRE9fIdgIhIVZSgRCRYSlAiEiwlKBEJlhKUiARLCUpEgqUEtYMxszZm9qKZrTWzW2vRzq/M7J66jC0fzOwDM+uZ7zikckpQ1TCzo83sFTNbbWYrzWymmR1uZkea2Toz26WSc+aY2VAz28vM3MzmVChvZWYbzGxBNdc1M7vCzN6Pr1NkZg+a2UF18LKGACuAZu4+rKaNuPtN7n5JHcSTYGYXxr+32ysc7xcfH51lO6PN7Ia0eu5+gLu/ULNoZVtTgqqCmTUDngDuAloAHYDfAd+4+2tAEXBWhXMOBLoA4zMO7xQf3+Q84J8pl78D+DlwRXztfYFHgFNr+noy7Al86GGv0P0MONvMCjKODQI+qasLVGhbQuXu2irZgG5ASTXlvwKeq3DsFuDh+Oe9AAf+G/hjRp03gV8DC6potzNQBhxRzbULgbHAcuDz+Br14rILgZeBPwGriJJhn7hsNLAR2AD8CzgxPnZDRts9gaKM/auBxcBa4GOgV3z8t8DfM+r9CPgAKAFeAL6XUbYA+E/gXWA1MBFoXMVr2xT/U8Cp8bEWQDHwR2B0Rt0H4+OrgReBA+LjQyq8zscz4rg6juMboCA+dmJcPg24NaP9CcC9+f5/cUfe1IOq2idAmZmNMbM+ZrZrhfJxwLFmtjuAmdUj6h2NqVDv70B/M6tvZl2AXYBZ1Vy3F1GCeL2aOncRJalOwHHABcBFGeXdiZJJK6KkOcrMzN0vBO4HbnH3Xdz92WqugZntBwwFDnf3psDJRG/oivX2Jeo1Xgm0JnqjP25mDTOqnQ30BvYGDiZKRNUZG78ugP7Ao0RJJdOTRAl9N2B2/Npw9xEVXmffjHPOJeqJNnf30grtXQwMNLMTzGwAcARRT1byRAmqCu6+BjiaqBc0ElhuZo+ZWZu4fBFRT2FgfEovoBEwtUJTRUTJ4kSiN9y4lEu3BJZWVWhm9YnesNe6+1p3XwDcmhEHwOfuPtLdy4gSZjugTcp1K1NG9Jq6mFkDd1/g7p9VUu8cYKq7P+PuG4l6b02AH2TUudPdl7j7SuBx4NCUaz8M9DSzQqLf29iKFdz93vh38A1Rj+6QuH517nT3Re6+vpL2ioHLiH5ndwAXuPvalPZkG1KCqoa7z3X3C929I3Ag0B4YnlFlDN8mhoHAhPgNWtFYoh7DuaQnqC+JEkpVWgENiIZ2m3xONEe2SXHGa/gq/nGLCf007j6PqFf0W+ALM5tgZu0rqdo+Mx53LwcWVRUT8FVaPHECmUo0fG3p7jMzy+Me6c1m9pmZreHbnl2rlJe1KKX8caA+8LG7v5xSV7YxJagsuftHRPM1mRPeU4COZnY8cAZbDu82mUw0rJjv7gtTLjU9brNbFeUriOZX9sw4tgfRPFFNrAN2ythvm1no7g+4+9Hx9Rz4QyVtLMmMx8wM2L0WMW0yFhhGNEyu6DygH1HPtJBozg/ANoVeRZtpNwduBOYC7czs3K0JVuqeElQVzGx/MxtmZh3j/d2JekCvbarj7uuAh4D7iIZVb1bWVlzvBCD1try7fwr8BRhvZj3NrKGZNTaz/mZ2TTxsmwTcaGZNzWxP4CoqfxNn423gFDNrYWZtiXpMxK95v3g+phHwNbAeKK+kjUnAqWbWy8waECWVb4BXahjTJjOAHxLNuVXUNL7Gl0QJ9qYK5cuI5uiyZmbHEs3lXUB01/AuM+tQ/VmyLSlBVW0t0WTzLDNbR5SY3id682UaQ9R72GKOJJO7v1nF/E1lrgD+DNxNdFfsM+DfiYYfAJcT9XzmE93xegC4N8u2KxoHvEM0RHqa6A7bJo2Am4l6bcVEk9HXVmzA3T8GzidKJCuAvkBfd99Qw5g2tevuPj2et6poLNGwcjHwIRn/cMRGEc2dlZjZI2nXipeVjAWGuvtid38pbuO+uEcoeWDuIS+HEZEdmXpQIhIsJSgRCZYSlIgESwlKRIKlBCUiwdrmn+jeuGK+bhNup5q0PybfIUgtlG5YXKPlEdm8Zxu06pSTpRd65ISIJJVV9mmt/FCCEpGk8so+LJAfSlAikuBlFZ9Ckz9KUCKS5OpBiUioNAclIsHSHJSIhEpzUCISLg3xRCRYmiQXkWBpiCciwdIkuYiEyss1ByUioVIPSkSCpbt4IhIs3cUTkWDpLp6IBKtUCUpEAhV9eXUYlKBEJElDPBEJVkDLDPStLiKSVFaavqUws1+Y2Qdm9r6ZjTezxma2t5nNMrN5ZjbRzBqmtaMEJSJJXp6+VcPMOgBXAN3c/UCgPtAf+ANwu7vvA6wCBqeFogQlIkmlpelbugKgiZkVADsBS4ETgIfi8jHA6WmNKEGJSFIWQzwzG2Jmb2ZsQzad7u6LgT8BC4kS02rgLaDE3TdltyKgQ1oomiQXkaQsVpK7+whgRGVlZrYr0A/YGygBHgR61yQUJSgRSar9MoMTgX+6+3IAM5sC9ACam1lB3IvqCCxOa0hDPBFJKi9P36q3EDjSzHYyMwN6AR8CzwNnxXUGAY+mNaQEJSJJZWXpWzXcfRbRZPhs4D2iPDMCuBq4yszmAS2BUWmhaIgnIkl1sFDT3X8D/KbC4fnAEVvTjhKUiCTpoy4iEqyUIVwuKUGJSFJAn8VTghKRJA3xRCRUXu75DmEzJSgRSQqoB6V1UNUYN+kRTj//UvoN+AnjJj6cKBs9fjIH9ujDqpLVlZ776LRnOOWcwZxyzmAenfZMLsKVKowccStLit7h7TnTq6xz+23X89GHLzP7rWfoeuiBOYwuQOWevuWIElQVPp2/gMmPPcX4e4YzecxfmPHK6ywsWgLA0mXLeeX12bRrs1ul565es5a/3vcA40cOZ/zI4fz1vgdYvWZtLsOXDGPHTuLU0wZUWd6n9wl03mdv9u9yNJdddjV3//l/cxhdgOrmaQZ1QgmqCvMXLOKgA/ajSePGFBTUp9uhB/HsjJkA3HLn/3HVTwdjVvm5M2e9xVGHd6WwWVMKmzXlqMO7MnPWWzmMXjK99PIsVq4qqbK8b9+TGXd/9BSQWa/PprB5IW3bVv6Pzw6hlivJ61JqgjKz/c3sajO7M96uNrPv5SK4fNqn057MfucDSlavYf3XX/PSq29QvGw5z730Kru1bsX+nTtVee6y5Stou1vrzfttWrdi2fIVuQhbaqBD+7YULVqyeX9x0VI6tG+bx4jybHsZ4pnZ1cAEwIDX482A8WZ2TTXnbX5WzD1jx9dlvDnzb3vtwcUDfsyQX/yaS6+6jv06d2LDxo2MHDuRoZcMzHd4IttOQD2otLt4g4ED3D3xXchmdhvwAXBzZSdlPitm44r54dyz3Epn9j2ZM/ueDMDwv42mZYvmPPfiq5w56KdA1FP68cWXM2HkcFq1bLH5vDatW/HGnHc37y9bvoLDux6c2+Ala4uXFNNx9/ab9zt0bMfiJcV5jCi/PKCFmmlDvHKgfSXH28Vl32lfxvMWS4u/YPqMmfTrcyIvTp3A05PH8PTkMbRp3YoH770rkZwAenT/Pq+8PpvVa9ayes1aXnl9Nj26fz8fL0Gy8MQTTzNwQPQUkO5HHMaa1WsoLv4iz1Hl0XbUg7oSmG5mnwKL4mN7APsAQ7dlYCH4xa9uoGTNGgoKCvj1sJ/SrOkuVdZ9f+4nTHpkGtdfeyWFzZrykwvPpf8lPwfg0ovOo7BZ01yFLRX8fdzdHHfsUbRq1YIF89/kd9f/iQYNGgAwYuQ4pj05nd69T+DjuTP5av16LrnkqjxHnGcBLdQ09+qDMbN6RI9I2PT84MXAG57l149uz0O8HV2T9sfkOwSphdINi6u4z1y9df/TP/U9u/P1E2rU9tZKXUnu7uXAazmIRURCoKcZiEioQpokV4ISkaRSJSgRCVUWXzuVK0pQIpLg6kGJSLACWmagBCUiSaW6iycigfIyDfFEJFQa4olIqDRJLiLhCqgHpSdqikiCl3rqlsbMmpvZQ2b2kZnNNbOjzKyFmT1jZp/G/901rR0lKBFJqpsnat4BPOXu+wOHAHOBa4Dp7t4ZmB7vV0sJSkQSatuDMrNC4FhgFIC7b3D3EqAfMCauNgY4PS0WJSgRScgmQWU+1jvehmQ0sTewHLjPzOaY2T1mtjPQxt2XxnWKgTZpsWiSXESSsriJl/lY70oUAIcBl7v7LDO7gwrDOXd3M0sdK6oHJSIJXpq+pSgCitx9Vrz/EFHCWmZm7QDi/6Y+V1kJSkQSvDx9q/Z892JgkZntFx/qBXwIPAYMio8NAh5Ni0VDPBFJyKKHlI3LgfvNrCEwH7iIqEM0ycwGA58DZ6c1ogQlIgl18Tgod38b6FZJUa+taUcJSkQSvCwn34eQFSUoEUkoL1WCEpFABfTEXyUoEUkq1xBPRELl5UpQIhIo9aBEJFjqQYlIsNSDEpFgKUGJSLDKXQlKRAJVXhbOMwSUoEQkwcP5zgQlKBFJKlMPSkRC5ZqDEpFQlWkdlIiEqnxHSlDNdj9+W19CtpGHWxyb7xAkD7TMQESCVVauSXIRCVRAqwyUoEQkST0oEQlWQA/UVIISkaQyTZKLSKjKAvo+XyUoEUnQEE9EglWGhngiEqiQelDhDDZFJAhlZqlbNsysvpnNMbMn4v29zWyWmc0zs4lm1jCtDSUoEUkox1K3LP0cmJux/wfgdnffB1gFDE5rQAlKRBLKstjSmFlH4FTgnnjfgBOAh+IqY4DT09pRghKRhGyGeGY2xMzezNiGVGhmOPBLvp3SagmUuHtpvF8EdEiLRZPkIpKQzSS5u48ARlRWZmanAV+4+1tm1rM2sShBiUhCaZaT4NXoAfzIzE4BGgPNgDuA5mZWEPeiOgKL0xrSEE9EEjyLrdrz3a91947uvhfQH3jO3QcAzwNnxdUGAY+mxaIEJSIJpZa+1dDVwFVmNo9oTmpU2gka4olIQl0+D8rdXwBeiH+eDxyxNecrQYlIQi16SHVOCUpEEkL6qIsSlIgklKkHJSKhymaleK4oQYlIQkBfi6cEJSJJpelVckYJSkQS9LVTIhIsLTMQkWCpByUiwSoNKEUpQYlIgpYZiEiwtMxARIJVpiGeiIRKn8UTkWCpByUiwVIPSkSCpR6UiARLCWo706hRI559dhINGzakoKCAhx+exg033J6o07BhQ0aNuo2uXQ9i5cpVnH/+UBYuLMpTxAJAPePYf9zE18UreX3gH+l6989ofkgnykvLKJnzGe/+1z146ZarfjqefSydr4y+U/LT4Y9QNOnFXEeeVyEN8fSlCVn45ptv6N37XLp370P37n046aTjOOKIrok6F154DqtWrebAA4/jrrtGceON1+QpWtmk03/0Ye2n336z0eIpM3n+6GHM6PlL6jduyB4Djt/inAbNd2bfYWfw8inX8XKf69h32Bk0KNw5l2HnXRmeuuWKElSW1q37CoAGDQooKGiAe/KPdNppP+T++ycDMGXKNHr27JHzGOVbjdu1YLcTu7Lw/uc3H/ti+tubfy6ZM48m7VpscV7rnoewYsZ7bCxZx8bV61gx4z1aH39ITmIORTmeuuWKElSW6tWrx2uvTWPhwtk899xLvPHG24ny9u3bUlS0BICysjLWrFlLy5a75iNUAQ74/QXM/f0D4FsOWKygPh3POoYvnn9ni7LG7XZl/ZKVm/fXL11J43Y71t/xO9GDMrOLqinb/L3tpaX/quklglJeXs6RR57CPvscSbduh9Kly775DkmqsNsPu7JhxRpWv/vPSssPuvlivnztI1bO+jjHkW0fyrPYcqU2PajfVVXg7iPcvZu7dyso2KUWlwjP6tVrmDHjFU46qWfi+JIlxXTs2B6A+vXr06xZU778clUeIpQWh+9Hm5MOo9cbd3LY366gVY8D6PrnnwGw77AzadSyKR/8Zlyl5369dBVN2n879GvSrgVfL92x/o7bTQ/KzN6tYnsPaJOjGPOuVasWFBY2A6Bx40b06nUMH388L1Fn6tRnGTDgTADOOOMUZsx4JedxSuSjmybw7GFDmX74Fcy+9E5WzPyAOUPvZo/zjqd1z4N567K7wCt/ky1/4R1a9zyYBoU706BwZ1r3PJjlL2w5FPwuK3NP3XIlbZlBG+BkoOI/IQbsMO/Atm13Y+TI26hfvx716tVj8uQnePLJ57juuquYPftdpk59ltGjJ3Lvvbfz/vszWLWqhIEDh+Y7bKngoFsGs75oBUc/cT0AS6e9wae3TaHwkE7seUEv3h02ko0l6/jk9oc55qkbAPjktilsLFmXz7BzLpeT4Gms4t2oRKHZKOA+d3+5krIH3P28tAs0abJnOK9Wtsqkwh/kOwSphb7F42v04JRz9jw99T078fNHqmzbzHYHxhJ1cBwY4e53mFkLYCKwF7AAONvdqx0/VzvEc/fBlSWnuCw1OYnI9qcOlhmUAsPcvQtwJPAzM+sCXANMd/fOwPR4v1paZiAiCbWdJHf3pe4+O/55LTAX6AD0A8bE1cYAp6fFogQlIgnunrplLiWKtyGVtWVmewFdgVlAG3dfGhcVk8WNNn0WT0QSsvnSBHcfAYyoro6Z7QJMBq509zVm305bububWeqFlKBEJKGsDpZimlkDouR0v7tPiQ8vM7N27r7UzNoBX6S1oyGeiCRkM8SrjkVdpVHAXHe/LaPoMWBQ/PMg4NG0WNSDEpGEOlgp3gMYCLxnZps+tPor4GZgkpkNBj4Hzk5rSAlKRBJqu1AzXppU1TqpXlvTlhKUiCSUVfIEiHxRghKRBA/ooy5KUCKSkMsPA6dRghKRhNKAnkquBCUiCWnLCHJJCUpEEupioWZdUYISkQT1oEQkWFpmICLBCumJmkpQIpKgHpSIBEsJSkSCpZXkIhIs9aBEJFjlWmYgIqEq97J8h7CZEpSIJGiZgYgES3NQIhKssnIlKBEJlJYZiEiwNMQTkWDpaQYiEizNQYlIsLTMQESCpR6UiARLk+QiEixNkotIsMrVgxKRUIXUg7KQgtkemdkQdx+R7zikZvT3C1u9fAfwHTAk3wFIrejvFzAlKBEJlhKUiARLCar2NH+xfdPfL2CaJBeRYKkHJSLBUoKqBTPrbWYfm9k8M7sm3/FI9szsXjP7wszez3csUjUlqBoys/rA3UAfoAtwrpl1yW9UshVGA73zHYRUTwmq5o4A5rn7fHffAEwA+uU5JsmSu78IrMx3HFI9Jaia6wAsytgvio+JSB1RghKRYClB1dxiYPeM/Y7xMRGpI0pQNfcG0NnM9jazhkB/4LE8xyTynaIEVUPuXgoMBf4BzAUmufsH+Y1KsmVm44FXgf3MrMjMBuc7JtmSVpKLSLDUgxKRYClBiUiwlKBEJFhKUCISLCUoEQmWEpSIBEsJSkSCpQQlIsH6f63hiSmchcK4AAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------------------\n",
      "Classification Report\n",
      "---------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.99      0.98      0.98        95\n",
      "           4       0.96      0.98      0.97        45\n",
      "\n",
      "    accuracy                           0.98       140\n",
      "   macro avg       0.97      0.98      0.98       140\n",
      "weighted avg       0.98      0.98      0.98       140\n",
      "\n"
     ]
    }
   ]
  }
 ]
}